{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zopiiiYD3Ud5"
      },
      "source": [
        "# Exercise: Build your own RAG pipeline\n",
        "*Participants notebook – complete the TODOs*\n",
        "\n",
        "Follow the numbered steps to reproduce the instructor's pipeline, but **use a Wikipedia article** instead of a PDF."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LTTilsbWDZg"
      },
      "source": [
        "## Welcome to the Workshop. Today we will explore the core concepts of RAG pipeline and build a very simple one. In the end, we will be able to ask quesions to our RAG system and get the desired reponse.\n",
        "\n",
        "___ For further assistance please check the following links___\n",
        "\n",
        "1. LangChain Documentation:  https://python.langchain.com/docs/how_to/\n",
        "2. Qdrant Vectorstore Documentation: https://qdrant.tech/documentation/concepts/\n",
        "3. Huggingface Documentaion: https://huggingface.co/docs\n",
        "3. OPENAI Documentation: https://platform.openai.com/docs/overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lav14YLMVOVI"
      },
      "source": [
        "#### Install and import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "A6qRF-yKYzAm",
        "outputId": "c4085a1b-364d-4d12-cbb4-6872eade6dc9"
      },
      "outputs": [],
      "source": [
        "%pip install langchain langchain-openai langchain-community langchain-chroma chromadb openai tiktoken pypdf wikipedia langchain_experimental qdrant-client\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1IpI0T4_Y6F_"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain.document_loaders import PyPDFLoader, WikipediaLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from langchain_chroma import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Qdrant\n",
        "from qdrant_client import QdrantClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P9ybqWD2Y9C7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "OPENAI_API_TOKEN = userdata.get('OPEN_API_KEY')\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl87TCZlTe9U"
      },
      "source": [
        "### 1 . Load a Wikipedia article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDOfeUt7ZPPY",
        "outputId": "2bc4cd9a-0e77-4e6f-9125-20ce478fd8d7"
      },
      "outputs": [],
      "source": [
        "#Load a wikipedia article using WikipediaLoader and print the document and its length\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxYPr2rSS0JK"
      },
      "source": [
        "### 2 . Chunk the text\n",
        "\n",
        "Explore LangChain's different Chunking Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5s0Yt4VBCMk",
        "outputId": "9c87dec0-de58-40e8-bf63-da542b00b2b1"
      },
      "outputs": [],
      "source": [
        "# TODO: try Semantic Chunking or Character Chunking\n",
        "#RecursiveCharacterTextSplitter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0ABqZHNSvPl",
        "outputId": "b2412be3-2abd-485e-82a8-33b4a5f0af96"
      },
      "outputs": [],
      "source": [
        "#CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiskCaj5GLsB",
        "outputId": "c408c240-88bb-495b-8fcb-8dffa5227e5a"
      },
      "outputs": [],
      "source": [
        "#SemanticChunker\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQlIJ_NnS6tH"
      },
      "source": [
        "### 3 . Embeddings &  vector‑stores\n",
        "Use the Embedding models from OpenAI and for Vector DB use QdRant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KmdzK0T1DGkr"
      },
      "outputs": [],
      "source": [
        "# TODO: embed & store\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jHdhEn-TUxU"
      },
      "source": [
        "### 4 . Similarity search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLo3jbUoDO3g",
        "outputId": "d8df235e-2d84-4cbc-ef4f-ca9ef6498e75"
      },
      "outputs": [],
      "source": [
        "# TODO: formulate your own query\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmOtu-cVTlqP"
      },
      "source": [
        "### 5 . Define the Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9Ag2ddHYD2RU"
      },
      "outputs": [],
      "source": [
        "# TODO: design a prompt template & run the chain\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZlp2hYVTzsV"
      },
      "source": [
        "###6. Build the Chain using LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "OdZRDa-IT_IB"
      },
      "outputs": [],
      "source": [
        "# TODO: Build the Chain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FTQgm-pnUCNw"
      },
      "outputs": [],
      "source": [
        "#Select an LLM Model with temperature\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1fvIalDZDv3z"
      },
      "outputs": [],
      "source": [
        "#RetrievalQA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNV2By3gUqjc"
      },
      "source": [
        "###7. Ask Questions to the RAG Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "WjuYBPSkUzQX",
        "outputId": "b04adf52-4d2f-44f4-b6bd-256a1b5c7411"
      },
      "outputs": [],
      "source": [
        "# TODO: Test the RAG Agent by asking Questions\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
